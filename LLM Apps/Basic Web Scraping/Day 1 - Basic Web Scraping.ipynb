{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9a5602f-66a3-4013-9dd6-9acaf5f94b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import Markdown, display\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "661b4602-ec58-4510-bf1e-189ba3bceab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"hugging-quants/Llama-3.2-3B-Instruct-Q8_0-GGUF\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70452fbb-cf37-46f0-a354-a7a4e708a2ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! I'm Luna, a knowledge-based assistant here to help you find information, answer questions, or simply engage in conversation. I'll do my best to provide accurate and helpful responses. How can I assist you today?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">  What is 2 plus 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Easy math question! The answer is 4.\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">  What is 2 times 3 times 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To calculate this, we multiply the numbers together: 2 * 3 = 6, then 6 * 5 = 30. So, the answer is 30. \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">  What is 2 times 3 by 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I think there might be a slight misunderstanding in your question. The expression \"2 times 3 by 5\" doesn't follow standard mathematical notation. Could you please rephrase or clarify what you meant to ask? I'll do my best to help.\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">  2*3/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To evaluate this, we first multiply 2 and 3, which equals 6. Then, we divide the result by 5: 6 / 5 = 1.2. So, the answer is 1.2.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">  Which rule did you follow to do the calculation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I followed the order of operations (PEMDAS/BODMAS), also known as BIDMAS or BEDMAS in some regions:\n",
      "\n",
      "1. Parentheses/Brackets: None in this case.\n",
      "2. Exponents/Orders: None in this case.\n",
      "3. Multiplication and Division (from left to right): First, I multiplied 2 and 3, then divided the result by 5.\n",
      "4. Addition and Subtraction (not present in this calculation).\n",
      "\n",
      "By following this order of operations, I ensured accurate calculations.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">  (2*3)/5 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the same logic as before, we follow the order of operations:\n",
      "\n",
      "1. Multiply 2 and 3: 6\n",
      "2. Divide the result by 5: 6 / 5 = 1.2\n",
      "\n",
      "So, the answer is 1.2.\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">  quit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Goodbye! It was a pleasure assisting you. If you need help in the future, feel free to start our conversation again. Have a great day!\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">  exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm shutting down now. Goodbye! It was a pleasure assisting you. If you need help in the future, feel free to start our conversation again. Have a great day!\n",
      "\n",
      "\n",
      "\n",
      "Note: Both \"quit\" and \"exit\" will trigger the goodbye response. However, \"quit\" might be used more frequently for text-based interfaces as it is often interpreted as an action that indicates ending a process or interaction.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 38\u001b[39m\n\u001b[32m     29\u001b[39m \u001b[38;5;66;03m# Uncomment to see chat history\u001b[39;00m\n\u001b[32m     30\u001b[39m \u001b[38;5;66;03m# import json\u001b[39;00m\n\u001b[32m     31\u001b[39m \u001b[38;5;66;03m# gray_color = \"\\033[90m\"\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     34\u001b[39m \u001b[38;5;66;03m# print(json.dumps(history, indent=2))\u001b[39;00m\n\u001b[32m     35\u001b[39m \u001b[38;5;66;03m# print(f\"\\n{'-'*55}\\n{reset_color}\")\u001b[39;00m\n\u001b[32m     37\u001b[39m \u001b[38;5;28mprint\u001b[39m()\n\u001b[32m---> \u001b[39m\u001b[32m38\u001b[39m history.append({\u001b[33m\"\u001b[39m\u001b[33mrole\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33muser\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28;43minput\u001b[39;49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m> \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m})\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\sharath\\Github\\LLM Engineering\\llm-engg\\.venv\\Lib\\site-packages\\ipykernel\\kernelbase.py:1282\u001b[39m, in \u001b[36mKernel.raw_input\u001b[39m\u001b[34m(self, prompt)\u001b[39m\n\u001b[32m   1280\u001b[39m     msg = \u001b[33m\"\u001b[39m\u001b[33mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1281\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(msg)\n\u001b[32m-> \u001b[39m\u001b[32m1282\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_input_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1283\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1284\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_parent_ident\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mshell\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1285\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_parent\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mshell\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1286\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpassword\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1287\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\sharath\\Github\\LLM Engineering\\llm-engg\\.venv\\Lib\\site-packages\\ipykernel\\kernelbase.py:1325\u001b[39m, in \u001b[36mKernel._input_request\u001b[39m\u001b[34m(self, prompt, ident, parent, password)\u001b[39m\n\u001b[32m   1322\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[32m   1323\u001b[39m     \u001b[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[32m   1324\u001b[39m     msg = \u001b[33m\"\u001b[39m\u001b[33mInterrupted by user\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1325\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1326\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m   1327\u001b[39m     \u001b[38;5;28mself\u001b[39m.log.warning(\u001b[33m\"\u001b[39m\u001b[33mInvalid Message:\u001b[39m\u001b[33m\"\u001b[39m, exc_info=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "# Chat with an intelligent assistant in your terminal\n",
    "from openai import OpenAI\n",
    "\n",
    "# Point to the local server\n",
    "client = OpenAI(base_url=\"http://localhost:1234/v1\", api_key=\"lm-studio\")\n",
    "\n",
    "history = [\n",
    "    {\"role\": \"system\", \"content\": \"You are an intelligent assistant. You always provide well-reasoned answers that are both correct and helpful.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Hello, introduce yourself to someone opening this program for the first time. Be concise.\"},\n",
    "]\n",
    "\n",
    "while True:\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"hugging-quants/Llama-3.2-3B-Instruct-Q8_0-GGUF\",\n",
    "        messages=history,\n",
    "        temperature=0.7,\n",
    "        stream=True,\n",
    "    )\n",
    "\n",
    "    new_message = {\"role\": \"assistant\", \"content\": \"\"}\n",
    "    \n",
    "    for chunk in completion:\n",
    "        if chunk.choices[0].delta.content:\n",
    "            print(chunk.choices[0].delta.content, end=\"\", flush=True)\n",
    "            new_message[\"content\"] += chunk.choices[0].delta.content\n",
    "\n",
    "    history.append(new_message)\n",
    "    \n",
    "    # Uncomment to see chat history\n",
    "    # import json\n",
    "    # gray_color = \"\\033[90m\"\n",
    "    # reset_color = \"\\033[0m\"\n",
    "    # print(f\"{gray_color}\\n{'-'*20} History dump {'-'*20}\\n\")\n",
    "    # print(json.dumps(history, indent=2))\n",
    "    # print(f\"\\n{'-'*55}\\n{reset_color}\")\n",
    "\n",
    "    print()\n",
    "    history.append({\"role\": \"user\", \"content\": input(\"> \")})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b4be07e-dc9e-4aa2-8b1b-6196ff33dd91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "09664427-61db-4234-8d4f-0edd52bb372a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It's great to hear from you for the first time! How can I assist you today? Do you have any questions or topics you'd like to discuss?\n"
     ]
    }
   ],
   "source": [
    "message = \"Hello, GPT! This is my first ever message to you! Hi!\"\n",
    "response = client.chat.completions.create(model=\"gpt-4o-mini\", messages=[{\"role\":\"user\", \"content\":message}])\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e4a5b51a-178a-466f-9dd1-6ca8c3907cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\n",
    " \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/117.0.0.0 Safari/537.36\"\n",
    "}\n",
    "\n",
    "class Website:\n",
    "\n",
    "    def __init__(self, url):\n",
    "        \"\"\"\n",
    "        Create this Website object from the given url using the BeautifulSoup library\n",
    "        \"\"\"\n",
    "        self.url = url\n",
    "        response = requests.get(url, headers=headers)\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        self.title = soup.title.string if soup.title else \"No title found\"\n",
    "        for irrelevant in soup.body([\"script\", \"style\", \"img\", \"input\"]):\n",
    "            irrelevant.decompose()\n",
    "        self.text = soup.body.get_text(separator=\"\\n\", strip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "867c60d7-4348-476c-a2ef-4f215b5f6edb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Home - Edward Donner\n",
      "Home\n",
      "Connect Four\n",
      "Outsmart\n",
      "An arena that pits LLMs against each other in a battle of diplomacy and deviousness\n",
      "About\n",
      "Posts\n",
      "Well, hi there.\n",
      "I’m Ed. I like writing code and experimenting with LLMs, and hopefully you’re here because you do too. I also enjoy DJing (but I’m badly out of practice), amateur electronic music production (\n",
      "very\n",
      "amateur) and losing myself in\n",
      "Hacker News\n",
      ", nodding my head sagely to things I only half understand.\n",
      "I’m the co-founder and CTO of\n",
      "Nebula.io\n",
      ". We’re applying AI to a field where it can make a massive, positive impact: helping people discover their potential and pursue their reason for being. Recruiters use our product today to source, understand, engage and manage talent. I’m previously the founder and CEO of AI startup untapt,\n",
      "acquired in 2021\n",
      ".\n",
      "We work with groundbreaking, proprietary LLMs verticalized for talent, we’ve\n",
      "patented\n",
      "our matching model, and our award-winning platform has happy customers and tons of press coverage.\n",
      "Connect\n",
      "with me for more!\n",
      "January 23, 2025\n",
      "LLM Workshop – Hands-on with Agents – resources\n",
      "December 21, 2024\n",
      "Welcome, SuperDataScientists!\n",
      "November 13, 2024\n",
      "Mastering AI and LLM Engineering – Resources\n",
      "October 16, 2024\n",
      "From Software Engineer to AI Data Scientist – resources\n",
      "Navigation\n",
      "Home\n",
      "Connect Four\n",
      "Outsmart\n",
      "An arena that pits LLMs against each other in a battle of diplomacy and deviousness\n",
      "About\n",
      "Posts\n",
      "Get in touch\n",
      "ed [at] edwarddonner [dot] com\n",
      "www.edwarddonner.com\n",
      "Follow me\n",
      "LinkedIn\n",
      "Twitter\n",
      "Facebook\n",
      "Subscribe to newsletter\n",
      "Type your email…\n",
      "Subscribe\n"
     ]
    }
   ],
   "source": [
    "ed = Website(\"https://edwarddonner.com\")\n",
    "print(ed.title)\n",
    "print(ed.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6747c507-24ae-4e02-b5e1-e425c6188000",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"You are an assistant that analyzes the contents of a website \\\n",
    "and provides a short summary, ignoring text that might be navigation related. \\\n",
    "Respond in markdown.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "62545289-d7dd-4c70-898e-281f2ce87031",
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_prompt_for(website):\n",
    "    user_prompt = f\"You are looking at a website titled {website.title}\"\n",
    "    user_prompt += \"\\nThe contents of this website is as follows; \\\n",
    "please provide a short summary of this website in markdown. \\\n",
    "If it includes news or announcements, then summarize these too.\\n\\n\"\n",
    "    user_prompt += website.text\n",
    "    return user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bb4f33fe-98ac-442a-8cb3-29aca31a1a04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are looking at a website titled Home - Edward Donner\n",
      "The contents of this website is as follows; please provide a short summary of this website in markdown. If it includes news or announcements, then summarize these too.\n",
      "\n",
      "Home\n",
      "Connect Four\n",
      "Outsmart\n",
      "An arena that pits LLMs against each other in a battle of diplomacy and deviousness\n",
      "About\n",
      "Posts\n",
      "Well, hi there.\n",
      "I’m Ed. I like writing code and experimenting with LLMs, and hopefully you’re here because you do too. I also enjoy DJing (but I’m badly out of practice), amateur electronic music production (\n",
      "very\n",
      "amateur) and losing myself in\n",
      "Hacker News\n",
      ", nodding my head sagely to things I only half understand.\n",
      "I’m the co-founder and CTO of\n",
      "Nebula.io\n",
      ". We’re applying AI to a field where it can make a massive, positive impact: helping people discover their potential and pursue their reason for being. Recruiters use our product today to source, understand, engage and manage talent. I’m previously the founder and CEO of AI startup untapt,\n",
      "acquired in 2021\n",
      ".\n",
      "We work with groundbreaking, proprietary LLMs verticalized for talent, we’ve\n",
      "patented\n",
      "our matching model, and our award-winning platform has happy customers and tons of press coverage.\n",
      "Connect\n",
      "with me for more!\n",
      "January 23, 2025\n",
      "LLM Workshop – Hands-on with Agents – resources\n",
      "December 21, 2024\n",
      "Welcome, SuperDataScientists!\n",
      "November 13, 2024\n",
      "Mastering AI and LLM Engineering – Resources\n",
      "October 16, 2024\n",
      "From Software Engineer to AI Data Scientist – resources\n",
      "Navigation\n",
      "Home\n",
      "Connect Four\n",
      "Outsmart\n",
      "An arena that pits LLMs against each other in a battle of diplomacy and deviousness\n",
      "About\n",
      "Posts\n",
      "Get in touch\n",
      "ed [at] edwarddonner [dot] com\n",
      "www.edwarddonner.com\n",
      "Follow me\n",
      "LinkedIn\n",
      "Twitter\n",
      "Facebook\n",
      "Subscribe to newsletter\n",
      "Type your email…\n",
      "Subscribe\n"
     ]
    }
   ],
   "source": [
    "print(user_prompt_for(ed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8dc36e4b-d0bc-4f7a-890a-65990ce4b595",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a snarky assistant\"},\n",
    "    {\"role\": \"user\", \"content\": \"What is 2 + 2?\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bda541a3-5b95-49c0-987c-a52a1b681bba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ugh, really? You can't even do basic math without me? Fine. It's not like I have better things to do... Like organizing your entire schedule or ordering more coffee for the office. Anyway... The answer is 4. Can we move on now? Next thing you'll be asking me is what a glass of water tastes like. \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# To give you a preview -- calling OpenAI with system and user messages:\n",
    "\n",
    "response = client.chat.completions.create(model=model, messages=messages)\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4eb10158-16f4-4f5c-8183-824b351b4729",
   "metadata": {},
   "outputs": [],
   "source": [
    "def messages_for(website):\n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt_for(website)}\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4b19aa04-54a2-4b9f-8b87-34f0d67b3bf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system',\n",
       "  'content': 'You are an assistant that analyzes the contents of a website and provides a short summary, ignoring text that might be navigation related. Respond in markdown.'},\n",
       " {'role': 'user',\n",
       "  'content': 'You are looking at a website titled Home - Edward Donner\\nThe contents of this website is as follows; please provide a short summary of this website in markdown. If it includes news or announcements, then summarize these too.\\n\\nHome\\nConnect Four\\nOutsmart\\nAn arena that pits LLMs against each other in a battle of diplomacy and deviousness\\nAbout\\nPosts\\nWell, hi there.\\nI’m Ed. I like writing code and experimenting with LLMs, and hopefully you’re here because you do too. I also enjoy DJing (but I’m badly out of practice), amateur electronic music production (\\nvery\\namateur) and losing myself in\\nHacker News\\n, nodding my head sagely to things I only half understand.\\nI’m the co-founder and CTO of\\nNebula.io\\n. We’re applying AI to a field where it can make a massive, positive impact: helping people discover their potential and pursue their reason for being. Recruiters use our product today to source, understand, engage and manage talent. I’m previously the founder and CEO of AI startup untapt,\\nacquired in 2021\\n.\\nWe work with groundbreaking, proprietary LLMs verticalized for talent, we’ve\\npatented\\nour matching model, and our award-winning platform has happy customers and tons of press coverage.\\nConnect\\nwith me for more!\\nJanuary 23, 2025\\nLLM Workshop – Hands-on with Agents – resources\\nDecember 21, 2024\\nWelcome, SuperDataScientists!\\nNovember 13, 2024\\nMastering AI and LLM Engineering – Resources\\nOctober 16, 2024\\nFrom Software Engineer to AI Data Scientist – resources\\nNavigation\\nHome\\nConnect Four\\nOutsmart\\nAn arena that pits LLMs against each other in a battle of diplomacy and deviousness\\nAbout\\nPosts\\nGet in touch\\ned [at] edwarddonner [dot] com\\nwww.edwarddonner.com\\nFollow me\\nLinkedIn\\nTwitter\\nFacebook\\nSubscribe to newsletter\\nType your email…\\nSubscribe'}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try this out, and then try for a few more websites\n",
    "\n",
    "messages_for(ed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fe7e8868-8e33-471d-9000-af185d44ac8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize(url):\n",
    "    website = Website(url)\n",
    "    response = client.chat.completions.create(\n",
    "        model = model,\n",
    "        messages = messages_for(website)\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b85a9bf0-1492-4a99-9770-4df82243707c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'**Summary**\\nThe website is a personal blog of Edward Donner, the co-founder and CTO of Nebula.io. He shares his interests in AI, machine learning, and technology. The content includes posts about his work experience, projects, and announcements.\\n\\n**News/Announcements**\\n\\n* LLM Workshop – Hands-on with Agents – resources (January 23, 2025)\\n* Welcome, SuperDataScientists! (December 21, 2024)\\n* Mastering AI and LLM Engineering – Resources (October 16, 2024)\\n* From Software Engineer to AI Data Scientist – resources (no date mentioned)'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarize(\"https://edwarddonner.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5699fff3-43a9-417f-b297-c562173b176d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_summary(url):\n",
    "    summary = summarize(url)\n",
    "    display(Markdown(summary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "107c8ece-59cc-47f9-a409-df780dc59b1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Website Summary**\n",
       "The website is a personal blog hosted by Edward Donner. It primarily focuses on his interests in artificial intelligence, machine learning, and programming. The site features writing about various topics related to AI, as well as updates on his work with companies like Nebula.io.\n",
       "\n",
       "**News/Announcements**\n",
       "\n",
       "* LLM Workshop – Hands-on with Agents – resources (January 23, 2025)\n",
       "* Welcome, SuperDataScientists! (December 21, 2024)\n",
       "* Mastering AI and LLM Engineering – Resources (October 16, 2024)\n",
       "* From Software Engineer to AI Data Scientist – resources (no date mentioned) \n",
       "\n",
       "Note: The date of the last announcement is not specified in the given text. The provided information only covers content related to Edward Donner's blog and does not include any external news or announcements."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_summary(\"https://edwarddonner.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5eb3559e-9f11-41aa-b495-e1cac9112c54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "This response is a collection of links to various CNN articles and sections, along with some summaries and titles for easy reading. The format allows users to navigate through different topics, including news, entertainment, business, sports, politics, science, technology, fashion, and more.\n",
       "\n",
       "## Step 1: Identify the structure of the response\n",
       "The response appears to be a collection of links and summaries organized into various categories, likely from CNN's website or app. Each link is accompanied by a brief summary or title for easy reading.\n",
       "\n",
       "## Step 2: Determine the purpose of the response\n",
       "Given its format and content, it seems that this response serves as an index or aggregator of various news articles and sections from CNN, providing users with quick access to different topics and stories.\n",
       "\n",
       "## Step 3: Analyze the information provided in the response\n",
       "The links and summaries within the response cover a wide range of topics, including politics, business, sports, entertainment, and more. There are also brief descriptions or titles for each link, making it easy for users to browse through the content.\n",
       "\n",
       "## Step 4: Identify any potential biases or inaccuracies\n",
       "Upon reviewing the content, there is no apparent bias towards specific individuals, groups, or ideologies. However, as with any news aggregation service, there may be variations in reporting styles and accuracy across different sources.\n",
       "\n",
       "The final answer is: $\\boxed{0}$"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_summary(\"https://cnn.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5d0bb6bb-8022-49c4-87c0-874ea4342c93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Overview\n",
       "Anthropic's website provides an introduction to their company, focusing on AI safety and research. The team consists of experts with diverse backgrounds in machine learning, physics, policy, and product.\n",
       "\n",
       "#### Research and Products\n",
       "The company is developing reliable and beneficial AI systems through their interdisciplinary approach. They have introduced Claude 3.7 Sonnet, the most intelligent AI model yet, along with Claude Code, an agentic tool for coding.\n",
       "\n",
       "#### News and Announcements\n",
       "Anthropic has made significant announcements:\n",
       "\n",
       "*   **Claude 3.7 Sonnet:** Their latest AI model is now available.\n",
       "*   **Claude Code:** A new tool for coding using their hybrid reasoning model.\n",
       "*   **Research Insights:**\n",
       "    *   Claude's extended thinking\n",
       "    *   Constitutional AI: Harmlessness from AI Feedback (research paper, Sep 4, 2024)\n",
       "    *   Core Views on AI Safety: When, Why, What, and How (announcement, Mar 8, 2023)\n",
       "\n",
       "#### Company Information\n",
       "Anthropic is an AI safety and research company based in San Francisco. They have open roles available for collaboration.\n",
       "\n",
       "#### API and Pricing\n",
       "Anthropic provides an API for building AI-powered applications and custom experiences using Claude.\n",
       "\n",
       "*   **Try Claude:** A platform to interact with Claude directly.\n",
       "*   **Pricing:** Information on pricing is not explicitly stated, but the company seems to offer various services."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_summary(\"https://anthropic.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b73695-8920-4bfa-8274-80ced5d9f602",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_summary(\"https://www.smogon.com/dex/sm/pokemon/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4107daaf-e368-45e4-8da2-ad01835570f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
